{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network hybrid recommendation system on Google Analytics data model and training\n",
    "\n",
    "This notebook demonstrates how to implement a hybrid recommendation system using a neural network to combine content-based and collaborative filtering recommendation models using Google Analytics data. We are going to use the learned user embeddings from [wals.ipynb](../wals.ipynb) and combine that with our previous content-based features from [content_based_using_neural_networks.ipynb](../content_based_using_neural_networks.ipynb)\n",
    "\n",
    "Now that we have our data preprocessed from BigQuery and Cloud Dataflow, we can build our neural network hybrid recommendation model to our preprocessed data. Then we can train locally to make sure everything works and then use the power of Google Cloud ML Engine to scale it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use TensorFlow Hub to use trained text embeddings, so let's first pip install that and reset our session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_hub\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/f0/3a3ced04c8359e562f1b91918d9bde797c8a916fcfeddc8dc5d673d1be20/tensorflow_hub-0.3.0-py2.py3-none-any.whl (73kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 3.0MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from tensorflow_hub) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from tensorflow_hub) (1.14.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from tensorflow_hub) (3.6.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/envs/py3env/lib/python3.5/site-packages (from protobuf>=3.4.0->tensorflow_hub) (40.2.0)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now reset the notebook's session kernel! Since we're no longer using Cloud Dataflow, we'll be using the python3 kernel from here on out so don't forget to change the kernel if it's still python2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import helpful libraries and setup our project, bucket, and region\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "PROJECT = 'qwiklabs-gcp-57137d462d1cebb5' # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = 'qwiklabs-gcp-57137d462d1cebb5' # REPLACE WITH YOUR BUCKET NAME\n",
    "REGION = 'us-east1' # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
    "\n",
    "# do not change these\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = '1.8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating gs://qwiklabs-gcp-57137d462d1cebb5/...\n",
      "BadRequestException: 400 Invalid Value\n",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/features/eval.csv-00000-of-00001 [Content-Type=text/plain]...\n",
      "/ [0 files][    0.0 B/ 11.4 MiB]                                                \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/features/tmp/staging/preprocess-hybrid-recommendation-features-181217-164834.1545065316.946936/apache_beam-2.9.0-cp27-cp27mu-manylinux1_x86_64.whl [Content-Type=application/octet-stream]...\n",
      "/ [0 files][    0.0 B/ 13.6 MiB]                                                \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/features/tmp/staging/preprocess-hybrid-recommendation-features-181217-164834.1545065316.946936/dataflow_python_sdk.tar [Content-Type=application/octet-stream]...\n",
      "/ [0 files][    0.0 B/ 16.0 MiB]                                                \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/features/tmp/staging/preprocess-hybrid-recommendation-features-181217-164834.1545065316.946936/pipeline.pb [Content-Type=application/octet-stream]...\n",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/features/train.csv-00000-of-00004 [Content-Type=text/plain]...\n",
      "/ [0 files][    0.0 B/ 16.1 MiB]                                                \r",
      "/ [0 files][    0.0 B/ 18.0 MiB]                                                \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/features/train.csv-00001-of-00004 [Content-Type=text/plain]...\n",
      "-\r",
      "- [1/21 files][  2.4 MiB/128.8 MiB]   1% Done                                   \r",
      "- [1/21 files][  2.4 MiB/128.8 MiB]   1% Done                                   \r",
      "- [2/21 files][  2.4 MiB/128.8 MiB]   1% Done                                   \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/features/train.csv-00002-of-00004 [Content-Type=text/plain]...\n",
      "- [2/21 files][  2.4 MiB/128.8 MiB]   1% Done                                   \r",
      "- [3/21 files][  4.4 MiB/128.8 MiB]   3% Done                                   \r",
      "- [4/21 files][  6.7 MiB/128.8 MiB]   5% Done                                   \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/features/train.csv-00003-of-00004 [Content-Type=text/plain]...\n",
      "- [4/21 files][  6.7 MiB/128.8 MiB]   5% Done                                   \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocab_counts/author_vocab_count.txt-00000-of-00001 [Content-Type=text/plain]...\n",
      "- [4/21 files][  6.7 MiB/128.8 MiB]   5% Done                                   \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocab_counts/category_vocab_count.txt-00000-of-00001 [Content-Type=text/plain]...\n",
      "- [5/21 files][ 18.0 MiB/128.8 MiB]  14% Done                                   \r",
      "- [5/21 files][ 18.0 MiB/128.8 MiB]  14% Done                                   \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocab_counts/content_id_vocab_count.txt-00000-of-00001 [Content-Type=text/plain]...\n",
      "- [6/21 files][ 18.0 MiB/128.8 MiB]  14% Done                                   \r",
      "- [6/21 files][ 18.0 MiB/128.8 MiB]  14% Done                                   \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocab_counts/months_since_epoch_mean.txt-00000-of-00001 [Content-Type=text/plain]...\n",
      "\\\r",
      "\\ [7/21 files][ 18.0 MiB/128.8 MiB]  14% Done                                   \r",
      "\\ [7/21 files][ 18.0 MiB/128.8 MiB]  14% Done                                   \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocab_counts/tmp/staging/preprocess-hybrid-recommendation-vocab-counts-181217-170736.1545066458.457255/apache_beam-2.9.0-cp27-cp27mu-manylinux1_x86_64.whl [Content-Type=application/octet-stream]...\n",
      "\\ [8/21 files][ 18.0 MiB/128.8 MiB]  14% Done                                   \r",
      "\\ [8/21 files][ 18.0 MiB/128.8 MiB]  14% Done                                   \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocab_counts/tmp/staging/preprocess-hybrid-recommendation-vocab-counts-181217-170736.1545066458.457255/dataflow_python_sdk.tar [Content-Type=application/octet-stream]...\n",
      "\\ [9/21 files][ 39.3 MiB/128.8 MiB]  30% Done                                   \r",
      "\\ [9/21 files][ 39.3 MiB/128.8 MiB]  30% Done                                   \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocab_counts/tmp/staging/preprocess-hybrid-recommendation-vocab-counts-181217-170736.1545066458.457255/pipeline.pb [Content-Type=application/octet-stream]...\n",
      "\\ [10/21 files][ 68.6 MiB/128.8 MiB]  53% Done                                  \r",
      "\\ [10/21 files][ 68.6 MiB/128.8 MiB]  53% Done                                  \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocabs/author_vocab.txt-00000-of-00001 [Content-Type=text/plain]...\n",
      "\\ [11/21 files][ 68.6 MiB/128.8 MiB]  53% Done                                  \r",
      "\\ [11/21 files][ 68.6 MiB/128.8 MiB]  53% Done                                  \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocabs/category_vocab.txt-00000-of-00001 [Content-Type=text/plain]...\n",
      "|\r",
      "| [12/21 files][119.2 MiB/128.8 MiB]  92% Done                                  \r",
      "| [12/21 files][119.2 MiB/128.8 MiB]  92% Done                                  \r",
      "| [13/21 files][121.5 MiB/128.8 MiB]  94% Done                                  \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocabs/content_id_vocab.txt-00000-of-00001 [Content-Type=text/plain]...\n",
      "| [13/21 files][121.5 MiB/128.8 MiB]  94% Done                                  \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocabs/tmp/staging/preprocess-hybrid-recommendation-vocab-lists-181217-170024.1545066026.063994/apache_beam-2.9.0-cp27-cp27mu-manylinux1_x86_64.whl [Content-Type=application/octet-stream]...\n",
      "| [14/21 files][121.6 MiB/128.8 MiB]  94% Done                                  \r",
      "| [14/21 files][121.6 MiB/128.8 MiB]  94% Done                                  \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocabs/tmp/staging/preprocess-hybrid-recommendation-vocab-lists-181217-170024.1545066026.063994/dataflow_python_sdk.tar [Content-Type=application/octet-stream]...\n",
      "| [15/21 files][124.0 MiB/128.8 MiB]  96% Done                                  \r",
      "| [15/21 files][124.0 MiB/128.8 MiB]  96% Done                                  \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocabs/tmp/staging/preprocess-hybrid-recommendation-vocab-lists-181217-170024.1545066026.063994/pipeline.pb [Content-Type=application/octet-stream]...\n",
      "| [16/21 files][124.0 MiB/128.8 MiB]  96% Done                                  \r",
      "| [16/21 files][124.0 MiB/128.8 MiB]  96% Done                                  \r",
      "| [17/21 files][124.0 MiB/128.8 MiB]  96% Done                                  \r",
      "/\r",
      "/ [18/21 files][124.1 MiB/128.8 MiB]  96% Done                                  \r",
      "/ [19/21 files][126.4 MiB/128.8 MiB]  98% Done                                  \r",
      "/ [20/21 files][126.4 MiB/128.8 MiB]  98% Done                                  \r",
      "/ [21/21 files][128.8 MiB/128.8 MiB] 100% Done                                  \r\n",
      "Operation completed over 21 objects/128.8 MiB.                                   \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "if ! gsutil ls | grep -q gs://${BUCKET}/hybrid_recommendation/preproc; then\n",
    "  gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "  # copy canonical set of preprocessed files if you didn't do preprocessing notebook\n",
    "  gsutil -m cp -R gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation gs://${BUCKET}\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create hybrid recommendation system model using TensorFlow </h2>\n",
    "\n",
    "Now that we've created our training and evaluation input files as well as our categorical feature vocabulary files, we can create our TensorFlow hybrid recommendation system model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first get some of our aggregate information that we will use in the model from some of our preprocessed files we saved in Google Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.lib.io import file_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_content_ids = 15634\n"
     ]
    }
   ],
   "source": [
    "# Get number of content ids from text file in Google Cloud Storage\n",
    "with file_io.FileIO(tf.gfile.Glob(filename = \"gs://{}/hybrid_recommendation/preproc/vocab_counts/content_id_vocab_count.txt*\".format(BUCKET))[0], mode = 'r') as ifp:\n",
    "  number_of_content_ids = int([x for x in ifp][0])\n",
    "print(\"number_of_content_ids = {}\".format(number_of_content_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_categories = 3\n"
     ]
    }
   ],
   "source": [
    "# Get number of categories from text file in Google Cloud Storage\n",
    "with file_io.FileIO(tf.gfile.Glob(filename = \"gs://{}/hybrid_recommendation/preproc/vocab_counts/category_vocab_count.txt*\".format(BUCKET))[0], mode = 'r') as ifp:\n",
    "  number_of_categories = int([x for x in ifp][0])\n",
    "print(\"number_of_categories = {}\".format(number_of_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_authors = 1103\n"
     ]
    }
   ],
   "source": [
    "# Get number of authors from text file in Google Cloud Storage\n",
    "with file_io.FileIO(tf.gfile.Glob(filename = \"gs://{}/hybrid_recommendation/preproc/vocab_counts/author_vocab_count.txt*\".format(BUCKET))[0], mode = 'r') as ifp:\n",
    "  number_of_authors = int([x for x in ifp][0])\n",
    "print(\"number_of_authors = {}\".format(number_of_authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_months_since_epoch = 573.60733908\n"
     ]
    }
   ],
   "source": [
    "# Get mean months since epoch from text file in Google Cloud Storage\n",
    "with file_io.FileIO(tf.gfile.Glob(filename = \"gs://{}/hybrid_recommendation/preproc/vocab_counts/months_since_epoch_mean.txt*\".format(BUCKET))[0], mode = 'r') as ifp:\n",
    "  mean_months_since_epoch = float([x for x in ifp][0])\n",
    "print(\"mean_months_since_epoch = {}\".format(mean_months_since_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determine CSV and label columns\n",
    "NON_FACTOR_COLUMNS = 'next_content_id,visitor_id,content_id,category,title,author,months_since_epoch'.split(',')\n",
    "FACTOR_COLUMNS = [\"user_factor_{}\".format(i) for i in range(10)] + [\"item_factor_{}\".format(i) for i in range(10)]\n",
    "CSV_COLUMNS = NON_FACTOR_COLUMNS + FACTOR_COLUMNS\n",
    "LABEL_COLUMN = 'next_content_id'\n",
    "\n",
    "# Set default values for each CSV column\n",
    "NON_FACTOR_DEFAULTS = [[\"Unknown\"],[\"Unknown\"],[\"Unknown\"],[\"Unknown\"],[\"Unknown\"],[\"Unknown\"],[mean_months_since_epoch]]\n",
    "FACTOR_DEFAULTS = [[0.0] for i in range(10)] + [[0.0] for i in range(10)] # user and item\n",
    "DEFAULTS = NON_FACTOR_DEFAULTS + FACTOR_DEFAULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create input function for training and evaluation to read from our preprocessed CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create input function for train and eval\n",
    "def read_dataset(filename, mode, batch_size = 512):\n",
    "  def _input_fn():\n",
    "    def decode_csv(value_column):\n",
    "      columns = tf.decode_csv(records = value_column, record_defaults = DEFAULTS)\n",
    "      features = dict(zip(CSV_COLUMNS, columns))          \n",
    "      label = features.pop(LABEL_COLUMN)         \n",
    "      return features, label\n",
    "\n",
    "    # Create list of files that match pattern\n",
    "    file_list = tf.gfile.Glob(filename = filename)\n",
    "\n",
    "    # Create dataset from file list\n",
    "    dataset = tf.data.TextLineDataset(filenames = file_list).map(map_func = decode_csv)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      num_epochs = None # indefinitely\n",
    "      dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
    "    else:\n",
    "      num_epochs = 1 # end-of-input after this\n",
    "\n",
    "    dataset = dataset.repeat(count = num_epochs).batch(batch_size = batch_size)\n",
    "    return dataset.make_one_shot_iterator().get_next()\n",
    "  return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create our feature columns using our read in features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create feature columns to be used in model\n",
    "def create_feature_columns(args):\n",
    "  # Create content_id feature column\n",
    "  content_id_column = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    key = \"content_id\",\n",
    "    hash_bucket_size = number_of_content_ids)\n",
    "\n",
    "  # Embed content id into a lower dimensional representation\n",
    "  embedded_content_column = tf.feature_column.embedding_column(\n",
    "    categorical_column = content_id_column,\n",
    "    dimension = args['content_id_embedding_dimensions'])\n",
    "\n",
    "  # Create category feature column\n",
    "  categorical_category_column = tf.feature_column.categorical_column_with_vocabulary_file(\n",
    "    key = \"category\",\n",
    "    vocabulary_file = tf.gfile.Glob(filename = \"gs://{}/hybrid_recommendation/preproc/vocabs/category_vocab.txt*\".format(args['bucket']))[0],\n",
    "    num_oov_buckets = 1)\n",
    "\n",
    "  # Convert categorical category column into indicator column so that it can be used in a DNN\n",
    "  indicator_category_column = tf.feature_column.indicator_column(categorical_column = categorical_category_column)\n",
    "\n",
    "  # Create title feature column using TF Hub\n",
    "  embedded_title_column = hub.text_embedding_column(\n",
    "    key = \"title\", \n",
    "    module_spec = \"https://tfhub.dev/google/nnlm-de-dim50-with-normalization/1\",\n",
    "    trainable = False)\n",
    "\n",
    "  # Create author feature column\n",
    "  author_column = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    key = \"author\",\n",
    "    hash_bucket_size = number_of_authors + 1)\n",
    "\n",
    "  # Embed author into a lower dimensional representation\n",
    "  embedded_author_column = tf.feature_column.embedding_column(\n",
    "    categorical_column = author_column,\n",
    "    dimension = args['author_embedding_dimensions'])\n",
    "\n",
    "  # Create months since epoch boundaries list for our binning\n",
    "  months_since_epoch_boundaries = list(range(400, 700, 20))\n",
    "\n",
    "  # Create months_since_epoch feature column using raw data\n",
    "  months_since_epoch_column = tf.feature_column.numeric_column(\n",
    "    key = \"months_since_epoch\")\n",
    "\n",
    "  # Create bucketized months_since_epoch feature column using our boundaries\n",
    "  months_since_epoch_bucketized = tf.feature_column.bucketized_column(\n",
    "    source_column = months_since_epoch_column,\n",
    "    boundaries = months_since_epoch_boundaries)\n",
    "\n",
    "  # Cross our categorical category column and bucketized months since epoch column\n",
    "  crossed_months_since_category_column = tf.feature_column.crossed_column(\n",
    "    keys = [categorical_category_column, months_since_epoch_bucketized],\n",
    "    hash_bucket_size = len(months_since_epoch_boundaries) * (number_of_categories + 1))\n",
    "\n",
    "  # Convert crossed categorical category and bucketized months since epoch column into indicator column so that it can be used in a DNN\n",
    "  indicator_crossed_months_since_category_column = tf.feature_column.indicator_column(categorical_column = crossed_months_since_category_column)\n",
    "\n",
    "  # Create user and item factor feature columns from our trained WALS model\n",
    "  user_factors = [tf.feature_column.numeric_column(key = \"user_factor_\" + str(i)) for i in range(10)]\n",
    "  item_factors =  [tf.feature_column.numeric_column(key = \"item_factor_\" + str(i)) for i in range(10)]\n",
    "\n",
    "  # Create list of feature columns\n",
    "  feature_columns = [embedded_content_column,\n",
    "                     embedded_author_column,\n",
    "                     indicator_category_column,\n",
    "                     embedded_title_column,\n",
    "                     indicator_crossed_months_since_category_column] + user_factors + item_factors\n",
    "\n",
    "  return feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create our model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create custom model function for our custom estimator\n",
    "def model_fn(features, labels, mode, params):\n",
    "  # TODO: Create neural network input layer using our feature columns defined above\n",
    "  layer = tf.feature_column.input_layer(features, params['feature_columns'])\n",
    "\n",
    "  # TODO: Create hidden layers by looping through hidden unit list\n",
    "  for unit in params['hidden_units']:\n",
    "        layer = tf.layers.dense(layer, unit, tf.nn.relu)\n",
    "\n",
    "  # TODO: Compute logits (1 per class) using the output of our last hidden layer\n",
    "  logits = tf.layers.dense(layer, params['n_classes'])\n",
    "\n",
    "  # TODO: Find the predicted class indices based on the highest logit (which will result in the highest probability)\n",
    "  predicted_classes = tf.argmax(logits, axis = 1)\n",
    "\n",
    "  # Read in the content id vocabulary so we can tie the predicted class indices to their respective content ids\n",
    "  with file_io.FileIO(tf.gfile.Glob(filename = \"gs://{}/hybrid_recommendation/preproc/vocabs/content_id_vocab.txt*\".format(BUCKET))[0], mode = 'r') as ifp:\n",
    "    content_id_names = tf.constant(value = [x.rstrip() for x in ifp])\n",
    "\n",
    "  # Gather predicted class names based predicted class indices\n",
    "  predicted_class_names = tf.gather(params = content_id_names, indices = predicted_classes)\n",
    "\n",
    "  # If the mode is prediction\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    # Create predictions dict\n",
    "    predictions_dict = {\n",
    "        'class_ids': tf.expand_dims(input = predicted_classes, axis = -1),\n",
    "        'class_names' : tf.expand_dims(input = predicted_class_names, axis = -1),\n",
    "        'probabilities': tf.nn.softmax(logits = logits),\n",
    "        'logits': logits\n",
    "    }\n",
    "\n",
    "    # Create export outputs\n",
    "    export_outputs = {\"predict_export_outputs\": tf.estimator.export.PredictOutput(outputs = predictions_dict)}\n",
    "\n",
    "    return tf.estimator.EstimatorSpec( # return early since we're done with what we need for prediction mode\n",
    "      mode = mode,\n",
    "      predictions = predictions_dict,\n",
    "      loss = None,\n",
    "      train_op = None,\n",
    "      eval_metric_ops = None,\n",
    "      export_outputs = export_outputs)\n",
    "\n",
    "  # Continue on with training and evaluation modes\n",
    "\n",
    "  # Create lookup table using our content id vocabulary\n",
    "  table = tf.contrib.lookup.index_table_from_file(\n",
    "    vocabulary_file = tf.gfile.Glob(filename = \"gs://{}/hybrid_recommendation/preproc/vocabs/content_id_vocab.txt*\".format(BUCKET))[0])\n",
    "\n",
    "  # Look up labels from vocabulary table\n",
    "  labels = table.lookup(keys = labels)\n",
    "\n",
    "  # TODO: Compute loss using the correct type of softmax cross entropy since this is classification and our labels (content id indices) and probabilities are mutually exclusive\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels, logits)\n",
    "\n",
    "  # Compute evaluation metrics of total accuracy and the accuracy of the top k classes\n",
    "  accuracy = tf.metrics.accuracy(labels = labels, predictions = predicted_classes, name = 'acc_op')\n",
    "  top_k_accuracy = tf.metrics.mean(values = tf.nn.in_top_k(predictions = logits, targets = labels, k = params['top_k']))\n",
    "  map_at_k = tf.metrics.average_precision_at_k(labels = labels, predictions = predicted_classes, k = params['top_k'])\n",
    "\n",
    "  # Put eval metrics into a dictionary\n",
    "  eval_metrics = {\n",
    "    'accuracy': accuracy,\n",
    "    'top_k_accuracy': top_k_accuracy,\n",
    "    'map_at_k': map_at_k}\n",
    "\n",
    "  # Create scalar summaries to see in TensorBoard\n",
    "  tf.summary.scalar(name = 'accuracy', tensor = accuracy[1])\n",
    "  tf.summary.scalar(name = 'top_k_accuracy', tensor = top_k_accuracy[1])\n",
    "  tf.summary.scalar(name = 'map_at_k', tensor = map_at_k[1])\n",
    "\n",
    "  # Create scalar summaries to see in TensorBoard\n",
    "  tf.summary.scalar(name = 'accuracy', tensor = accuracy[1])\n",
    "  tf.summary.scalar(name = 'top_k_accuracy', tensor = top_k_accuracy[1])\n",
    "\n",
    "  # If the mode is evaluation\n",
    "  if mode == tf.estimator.ModeKeys.EVAL:\n",
    "    return tf.estimator.EstimatorSpec( # return early since we're done with what we need for evaluation mode\n",
    "        mode = mode,\n",
    "        predictions = None,\n",
    "        loss = loss,\n",
    "        train_op = None,\n",
    "        eval_metric_ops = eval_metrics,\n",
    "        export_outputs = None)\n",
    "\n",
    "  # Continue on with training mode\n",
    "\n",
    "  # If the mode is training\n",
    "  assert mode == tf.estimator.ModeKeys.TRAIN\n",
    "\n",
    "  # Create a custom optimizer\n",
    "  optimizer = tf.train.AdagradOptimizer(learning_rate = params['learning_rate'])\n",
    "\n",
    "  # Create train op\n",
    "  train_op = optimizer.minimize(loss = loss, global_step = tf.train.get_global_step())\n",
    "\n",
    "  return tf.estimator.EstimatorSpec( # final return since we're done with what we need for training mode\n",
    "    mode = mode,\n",
    "    predictions = None,\n",
    "    loss = loss,\n",
    "    train_op = train_op,\n",
    "    eval_metric_ops = None,\n",
    "    export_outputs = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a serving input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create serving input function\n",
    "def serving_input_fn():  \n",
    "  feature_placeholders = {\n",
    "    colname : tf.placeholder(dtype = tf.string, shape = [None]) \\\n",
    "    for colname in NON_FACTOR_COLUMNS[1:-1]\n",
    "  }\n",
    "  feature_placeholders['months_since_epoch'] = tf.placeholder(dtype = tf.float32, shape = [None])\n",
    "  \n",
    "  for colname in FACTOR_COLUMNS:\n",
    "    feature_placeholders[colname] = tf.placeholder(dtype = tf.float32, shape = [None])\n",
    "\n",
    "  features = {\n",
    "    key: tf.expand_dims(tensor, -1) \\\n",
    "    for key, tensor in feature_placeholders.items()\n",
    "  }\n",
    "    \n",
    "  return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all of the pieces are assembled let's create and run our train and evaluate loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create train and evaluate loop to combine all of the pieces together.\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "def train_and_evaluate(args):\n",
    "  estimator = tf.estimator.Estimator(\n",
    "    model_fn = model_fn,\n",
    "    model_dir = args['output_dir'],\n",
    "    params={\n",
    "      'feature_columns': create_feature_columns(args),\n",
    "      'hidden_units': args['hidden_units'],\n",
    "      'n_classes': number_of_content_ids,\n",
    "      'learning_rate': args['learning_rate'],\n",
    "      'top_k': args['top_k'],\n",
    "      'bucket': args['bucket']\n",
    "    })\n",
    "\n",
    "  train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn = read_dataset(filename = args['train_data_paths'], mode = tf.estimator.ModeKeys.TRAIN, batch_size = args['batch_size']),\n",
    "    max_steps = args['train_steps'])\n",
    "\n",
    "  exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "\n",
    "  eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn = read_dataset(filename = args['eval_data_paths'], mode = tf.estimator.ModeKeys.EVAL, batch_size = args['batch_size']),\n",
    "    steps = None,\n",
    "    start_delay_secs = args['start_delay_secs'],\n",
    "    throttle_secs = args['throttle_secs'],\n",
    "    exporters = exporter)\n",
    "\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run train_and_evaluate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocabulary_size = 3 in category is inferred from the number of elements in the vocabulary_file gs://qwiklabs-gcp-57137d462d1cebb5/hybrid_recommendation/preproc/vocabs/category_vocab.txt-00000-of-00001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:48:09.290319 139631768762112 tf_logging.py:116] vocabulary_size = 3 in category is inferred from the number of elements in the vocabulary_file gs://qwiklabs-gcp-57137d462d1cebb5/hybrid_recommendation/preproc/vocabs/category_vocab.txt-00000-of-00001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:48:35.687926 139631768762112 tf_logging.py:116] Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_num_worker_replicas': 1, '_session_config': None, '_service': None, '_task_type': 'worker', '_log_step_count_steps': 100, '_train_distribute': None, '_task_id': 0, '_num_ps_replicas': 0, '_save_summary_steps': 100, '_tf_random_seed': None, '_is_chief': True, '_save_checkpoints_secs': 600, '_keep_checkpoint_max': 5, '_save_checkpoints_steps': None, '_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efe6bb08c50>, '_global_id_in_cluster': 0, '_model_dir': 'hybrid_recommendation_trained'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:48:35.700114 139631768762112 tf_logging.py:116] Using config: {'_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_num_worker_replicas': 1, '_session_config': None, '_service': None, '_task_type': 'worker', '_log_step_count_steps': 100, '_train_distribute': None, '_task_id': 0, '_num_ps_replicas': 0, '_save_summary_steps': 100, '_tf_random_seed': None, '_is_chief': True, '_save_checkpoints_secs': 600, '_keep_checkpoint_max': 5, '_save_checkpoints_steps': None, '_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efe6bb08c50>, '_global_id_in_cluster': 0, '_model_dir': 'hybrid_recommendation_trained'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:48:35.710200 139631768762112 tf_logging.py:116] Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 30 secs (eval_spec.throttle_secs) or training is finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:48:35.714780 139631768762112 tf_logging.py:116] Start train and evaluate loop. The evaluate will happen after 30 secs (eval_spec.throttle_secs) or training is finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:48:36.364326 139631768762112 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:48:37.089723 139631768762112 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:48:53.030029 139631768762112 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:48:53.041168 139631768762112 tf_logging.py:116] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:48:53.793595 139631768762112 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:48:55.108993 139631768762112 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:48:56.137779 139631768762112 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:48:58.906047 139631768762112 tf_logging.py:116] Saving checkpoints for 1 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 1, loss = 9.657408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:48:59.385756 139631768762112 tf_logging.py:116] step = 1, loss = 9.657408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 6.4648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:14.853961 139631768762112 tf_logging.py:116] global_step/sec: 6.4648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 101, loss = 5.2848353 (15.479 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:14.864357 139631768762112 tf_logging.py:116] step = 101, loss = 5.2848353 (15.479 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 160 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:23.334132 139631768762112 tf_logging.py:116] Saving checkpoints for 160 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 5.1580067.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:24.435988 139631768762112 tf_logging.py:116] Loss for final step: 5.1580067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:24.579771 139631768762112 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:24.950744 139631768762112 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:25.628070 139631768762112 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-03-03-21:49:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:25.685102 139631768762112 tf_logging.py:116] Starting evaluation at 2019-03-03-21:49:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:25.815130 139631768762112 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:25.824954 139631768762112 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:26.300482 139631768762112 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:27.583243 139631768762112 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-03-03-21:49:46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:46.226706 139631768762112 tf_logging.py:116] Finished evaluation at 2019-03-03-21:49:46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 160: accuracy = 0.0010937927, global_step = 160, loss = 6.009516, map_at_k = 0.06901805555555562, top_k_accuracy = 0.1627798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:46.234607 139631768762112 tf_logging.py:116] Saving dict for global step 160: accuracy = 0.0010937927, global_step = 160, loss = 6.009516, map_at_k = 0.06901805555555562, top_k_accuracy = 0.1627798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:47.155784 139631768762112 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:47.777120 139631768762112 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:48.241916 139631768762112 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:48.265985 139631768762112 tf_logging.py:116] Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:48.272776 139631768762112 tf_logging.py:116] Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:48.275708 139631768762112 tf_logging.py:116] Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:48.319771 139631768762112 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:48.845177 139631768762112 tf_logging.py:116] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551649788'/assets\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:48.866106 139631768762112 tf_logging.py:116] Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551649788'/assets\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551649788'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:49.761029 139631768762112 tf_logging.py:116] SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551649788'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:49.936443 139631768762112 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:50.286787 139631768762112 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:51.499190 139631768762112 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:51.510966 139631768762112 tf_logging.py:116] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:51.677507 139631768762112 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:51.685508 139631768762112 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:52.337208 139631768762112 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:53.526463 139631768762112 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 161 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:55.926991 139631768762112 tf_logging.py:116] Saving checkpoints for 161 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 161, loss = 5.703103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:49:57.740097 139631768762112 tf_logging.py:116] step = 161, loss = 5.703103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 6.6926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:12.681585 139631768762112 tf_logging.py:116] global_step/sec: 6.6926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 261, loss = 4.999117 (14.965 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:12.705368 139631768762112 tf_logging.py:116] step = 261, loss = 4.999117 (14.965 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 321 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:21.553399 139631768762112 tf_logging.py:116] Saving checkpoints for 321 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 4.953226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:24.823159 139631768762112 tf_logging.py:116] Loss for final step: 4.953226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:24.965111 139631768762112 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:25.305970 139631768762112 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:26.276182 139631768762112 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-03-03-21:50:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:26.309705 139631768762112 tf_logging.py:116] Starting evaluation at 2019-03-03-21:50:26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:26.433747 139631768762112 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:26.440717 139631768762112 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:26.995395 139631768762112 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:28.233285 139631768762112 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-03-03-21:50:47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:47.430059 139631768762112 tf_logging.py:116] Finished evaluation at 2019-03-03-21:50:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 321: accuracy = 0.022188367, global_step = 321, loss = 5.8829846, map_at_k = 0.06517162698412704, top_k_accuracy = 0.16012344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:47.438729 139631768762112 tf_logging.py:116] Saving dict for global step 321: accuracy = 0.022188367, global_step = 321, loss = 5.8829846, map_at_k = 0.06517162698412704, top_k_accuracy = 0.16012344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:48.171457 139631768762112 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:48.493012 139631768762112 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:49.034651 139631768762112 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:49.058725 139631768762112 tf_logging.py:116] Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:49.066864 139631768762112 tf_logging.py:116] Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:49.069500 139631768762112 tf_logging.py:116] Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:49.114710 139631768762112 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:49.605659 139631768762112 tf_logging.py:116] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551649849'/assets\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:49.627190 139631768762112 tf_logging.py:116] Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551649849'/assets\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551649849'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:50.476752 139631768762112 tf_logging.py:116] SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551649849'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:50.672834 139631768762112 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:51.096392 139631768762112 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:52.086117 139631768762112 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:52.098628 139631768762112 tf_logging.py:116] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:52.245976 139631768762112 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:52.254286 139631768762112 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:52.906053 139631768762112 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:54.145764 139631768762112 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 322 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:56.212094 139631768762112 tf_logging.py:116] Saving checkpoints for 322 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 322, loss = 5.588605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:50:57.288767 139631768762112 tf_logging.py:116] step = 322, loss = 5.588605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 6.51109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:12.646859 139631768762112 tf_logging.py:116] global_step/sec: 6.51109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 422, loss = 5.126601 (15.368 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:12.656257 139631768762112 tf_logging.py:116] step = 422, loss = 5.126601 (15.368 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 486 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:22.192627 139631768762112 tf_logging.py:116] Saving checkpoints for 486 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 4.891279.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:23.353004 139631768762112 tf_logging.py:116] Loss for final step: 4.891279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:23.494830 139631768762112 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:23.874529 139631768762112 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:24.540557 139631768762112 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-03-03-21:51:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:24.573405 139631768762112 tf_logging.py:116] Starting evaluation at 2019-03-03-21:51:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:24.703385 139631768762112 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:24.711126 139631768762112 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:25.324944 139631768762112 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:26.519846 139631768762112 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-03-03-21:51:44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:44.921452 139631768762112 tf_logging.py:116] Finished evaluation at 2019-03-03-21:51:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 486: accuracy = 0.019336693, global_step = 486, loss = 5.8623004, map_at_k = 0.06559543650793656, top_k_accuracy = 0.15742803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:44.929976 139631768762112 tf_logging.py:116] Saving dict for global step 486: accuracy = 0.019336693, global_step = 486, loss = 5.8623004, map_at_k = 0.06559543650793656, top_k_accuracy = 0.15742803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:45.599014 139631768762112 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:46.243987 139631768762112 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:46.695589 139631768762112 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:46.721646 139631768762112 tf_logging.py:116] Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:46.737414 139631768762112 tf_logging.py:116] Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:46.740929 139631768762112 tf_logging.py:116] Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:46.821135 139631768762112 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:47.356055 139631768762112 tf_logging.py:116] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551649906'/assets\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:47.379212 139631768762112 tf_logging.py:116] Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551649906'/assets\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551649906'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:48.210533 139631768762112 tf_logging.py:116] SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551649906'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:48.399787 139631768762112 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:48.779948 139631768762112 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:50.067534 139631768762112 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:50.080502 139631768762112 tf_logging.py:116] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:50.230922 139631768762112 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:50.239448 139631768762112 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:50.861371 139631768762112 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:51.872846 139631768762112 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 487 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:56.863737 139631768762112 tf_logging.py:116] Saving checkpoints for 487 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 487, loss = 5.26518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:51:57.400249 139631768762112 tf_logging.py:116] step = 487, loss = 5.26518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 6.61146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:12.525246 139631768762112 tf_logging.py:116] global_step/sec: 6.61146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 587, loss = 4.9570427 (15.135 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:12.535339 139631768762112 tf_logging.py:116] step = 587, loss = 4.9570427 (15.135 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 639 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:20.220436 139631768762112 tf_logging.py:116] Saving checkpoints for 639 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 4.7639446.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:23.456006 139631768762112 tf_logging.py:116] Loss for final step: 4.7639446.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:23.599442 139631768762112 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:23.982177 139631768762112 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:24.930660 139631768762112 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-03-03-21:52:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:24.967755 139631768762112 tf_logging.py:116] Starting evaluation at 2019-03-03-21:52:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:25.097681 139631768762112 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:25.104932 139631768762112 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:25.674075 139631768762112 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:26.663243 139631768762112 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-03-03-21:52:45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:45.643832 139631768762112 tf_logging.py:116] Finished evaluation at 2019-03-03-21:52:45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 639: accuracy = 0.022657136, global_step = 639, loss = 5.7900257, map_at_k = 0.047040674603174584, top_k_accuracy = 0.18719481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:45.651180 139631768762112 tf_logging.py:116] Saving dict for global step 639: accuracy = 0.022657136, global_step = 639, loss = 5.7900257, map_at_k = 0.047040674603174584, top_k_accuracy = 0.18719481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:46.326671 139631768762112 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:46.640280 139631768762112 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:47.114502 139631768762112 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:47.139085 139631768762112 tf_logging.py:116] Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:47.146852 139631768762112 tf_logging.py:116] Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:47.152198 139631768762112 tf_logging.py:116] Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:47.202801 139631768762112 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:47.686498 139631768762112 tf_logging.py:116] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551649967'/assets\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:47.706231 139631768762112 tf_logging.py:116] Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551649967'/assets\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551649967'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:48.480179 139631768762112 tf_logging.py:116] SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551649967'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:48.656093 139631768762112 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:49.043370 139631768762112 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:49.986116 139631768762112 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:49.998484 139631768762112 tf_logging.py:116] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:50.382109 139631768762112 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:50.390980 139631768762112 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:50.975623 139631768762112 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:52.003303 139631768762112 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 640 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:53.741154 139631768762112 tf_logging.py:116] Saving checkpoints for 640 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 640, loss = 5.3106775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:52:56.959458 139631768762112 tf_logging.py:116] step = 640, loss = 5.3106775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 6.64483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:12.008295 139631768762112 tf_logging.py:116] global_step/sec: 6.64483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 740, loss = 4.7936773 (15.059 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:12.018231 139631768762112 tf_logging.py:116] step = 740, loss = 4.7936773 (15.059 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 797 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:20.023269 139631768762112 tf_logging.py:116] Saving checkpoints for 797 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 4.944474.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:20.930225 139631768762112 tf_logging.py:116] Loss for final step: 4.944474.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:21.080505 139631768762112 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:21.416832 139631768762112 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:22.104279 139631768762112 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-03-03-21:53:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:22.138355 139631768762112 tf_logging.py:116] Starting evaluation at 2019-03-03-21:53:22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:22.264476 139631768762112 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:22.272097 139631768762112 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:22.843384 139631768762112 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:23.855062 139631768762112 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-03-03-21:53:41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:41.909495 139631768762112 tf_logging.py:116] Finished evaluation at 2019-03-03-21:53:41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 797: accuracy = 0.02968866, global_step = 797, loss = 5.669377, map_at_k = 0.047326388888888876, top_k_accuracy = 0.19930466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:41.918033 139631768762112 tf_logging.py:116] Saving dict for global step 797: accuracy = 0.02968866, global_step = 797, loss = 5.669377, map_at_k = 0.047326388888888876, top_k_accuracy = 0.19930466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:42.563267 139631768762112 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:43.249114 139631768762112 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:43.697589 139631768762112 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:43.723123 139631768762112 tf_logging.py:116] Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:43.730101 139631768762112 tf_logging.py:116] Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:43.732502 139631768762112 tf_logging.py:116] Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:43.802195 139631768762112 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:44.304110 139631768762112 tf_logging.py:116] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551650023'/assets\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:44.326384 139631768762112 tf_logging.py:116] Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551650023'/assets\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551650023'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:45.001438 139631768762112 tf_logging.py:116] SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551650023'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:45.174264 139631768762112 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:45.520767 139631768762112 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:46.803704 139631768762112 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:46.815541 139631768762112 tf_logging.py:116] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:46.970209 139631768762112 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:46.978542 139631768762112 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:47.598175 139631768762112 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:48.844841 139631768762112 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 798 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:51.831770 139631768762112 tf_logging.py:116] Saving checkpoints for 798 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 798, loss = 5.4432354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:53:52.998326 139631768762112 tf_logging.py:116] step = 798, loss = 5.4432354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 6.59855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:08.152919 139631768762112 tf_logging.py:116] global_step/sec: 6.59855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 898, loss = 5.057993 (15.165 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:08.163491 139631768762112 tf_logging.py:116] step = 898, loss = 5.057993 (15.165 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 961 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:16.912466 139631768762112 tf_logging.py:116] Saving checkpoints for 961 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 4.996922.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:20.361896 139631768762112 tf_logging.py:116] Loss for final step: 4.996922.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:20.512082 139631768762112 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:21.063836 139631768762112 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:21.728311 139631768762112 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-03-03-21:54:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:21.758253 139631768762112 tf_logging.py:116] Starting evaluation at 2019-03-03-21:54:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:21.887479 139631768762112 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:21.893665 139631768762112 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:22.288912 139631768762112 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:23.268013 139631768762112 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-03-03-21:54:41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:41.822257 139631768762112 tf_logging.py:116] Finished evaluation at 2019-03-03-21:54:41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 961: accuracy = 0.024415016, global_step = 961, loss = 5.6624064, map_at_k = 0.043196626984126955, top_k_accuracy = 0.18500723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:41.829944 139631768762112 tf_logging.py:116] Saving dict for global step 961: accuracy = 0.024415016, global_step = 961, loss = 5.6624064, map_at_k = 0.043196626984126955, top_k_accuracy = 0.18500723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:42.488721 139631768762112 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:42.842659 139631768762112 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:43.280492 139631768762112 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:43.309173 139631768762112 tf_logging.py:116] Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:43.316957 139631768762112 tf_logging.py:116] Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:43.319670 139631768762112 tf_logging.py:116] Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:43.365121 139631768762112 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:43.885683 139631768762112 tf_logging.py:116] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551650083'/assets\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:43.909677 139631768762112 tf_logging.py:116] Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551650083'/assets\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551650083'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:44.697966 139631768762112 tf_logging.py:116] SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551650083'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:44.932955 139631768762112 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:45.262154 139631768762112 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:46.155824 139631768762112 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:46.165867 139631768762112 tf_logging.py:116] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:46.496687 139631768762112 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:46.503929 139631768762112 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:47.024266 139631768762112 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:47.999683 139631768762112 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 962 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:49.593076 139631768762112 tf_logging.py:116] Saving checkpoints for 962 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 962, loss = 5.0850835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:51.421735 139631768762112 tf_logging.py:116] step = 962, loss = 5.0850835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:57.292409 139631768762112 tf_logging.py:116] Saving checkpoints for 1000 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 4.583831.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:59.193412 139631768762112 tf_logging.py:116] Loss for final step: 4.583831.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:59.321357 139631768762112 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:54:59.646795 139631768762112 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:55:00.321073 139631768762112 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-03-03-21:55:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:55:00.352363 139631768762112 tf_logging.py:116] Starting evaluation at 2019-03-03-21:55:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:55:00.474009 139631768762112 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:55:00.480836 139631768762112 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:55:00.914310 139631768762112 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:55:01.894332 139631768762112 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-03-03-21:55:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:55:20.004817 139631768762112 tf_logging.py:116] Finished evaluation at 2019-03-03-21:55:20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.032774717, global_step = 1000, loss = 5.653212, map_at_k = 0.0536968253968254, top_k_accuracy = 0.20547678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:55:20.012084 139631768762112 tf_logging.py:116] Saving dict for global step 1000: accuracy = 0.032774717, global_step = 1000, loss = 5.653212, map_at_k = 0.0536968253968254, top_k_accuracy = 0.20547678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:55:20.643961 139631768762112 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:55:21.295364 139631768762112 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:55:21.742106 139631768762112 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:55:21.762687 139631768762112 tf_logging.py:116] Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:55:21.769832 139631768762112 tf_logging.py:116] Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:55:21.772679 139631768762112 tf_logging.py:116] Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:55:21.843108 139631768762112 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:55:22.334373 139631768762112 tf_logging.py:116] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551650121'/assets\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:55:22.355035 139631768762112 tf_logging.py:116] Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551650121'/assets\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551650121'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0303 21:55:23.198611 139631768762112 tf_logging.py:116] SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1551650121'/saved_model.pb\"\n"
     ]
    }
   ],
   "source": [
    "# Call train and evaluate loop\n",
    "import shutil\n",
    "\n",
    "outdir = 'hybrid_recommendation_trained'\n",
    "shutil.rmtree(outdir, ignore_errors = True) # start fresh each time\n",
    "\n",
    "arguments = {\n",
    "  'bucket': BUCKET,\n",
    "  'train_data_paths': \"gs://{}/hybrid_recommendation/preproc/features/train.csv*\".format(BUCKET),\n",
    "  'eval_data_paths': \"gs://{}/hybrid_recommendation/preproc/features/eval.csv*\".format(BUCKET),\n",
    "  'output_dir': outdir,\n",
    "  'batch_size': 128,\n",
    "  'learning_rate': 0.1,\n",
    "  'hidden_units': [256, 128, 64],\n",
    "  'content_id_embedding_dimensions': 10,\n",
    "  'author_embedding_dimensions': 10,\n",
    "  'top_k': 10,\n",
    "  'train_steps': 1000,\n",
    "  'start_delay_secs': 30,\n",
    "  'throttle_secs': 30\n",
    "}\n",
    "\n",
    "train_and_evaluate(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on module locally\n",
    "\n",
    "Now let's place our code into a python module with model.py and task.py files so that we can train using Google Cloud's ML Engine! First, let's test our module locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%writefile requirements.txt\n",
    "tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket=qwiklabs-gcp-57137d462d1cebb5\n",
      "number_of_content_ids = 15634\n",
      "number_of_categories = 3\n",
      "number_of_authors = 1103\n",
      "mean_months_since_epoch = 573.60733908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0303 21:56:30.672318 140155275327232 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n",
      "INFO:tensorflow:vocabulary_size = 3 in category is inferred from the number of elements in the vocabulary_file gs://qwiklabs-gcp-57137d462d1cebb5/hybrid_recommendation/preproc/vocabs/category_vocab.txt-00000-of-00001.\n",
      "I0303 21:56:32.156338 140155275327232 tf_logging.py:116] vocabulary_size = 3 in category is inferred from the number of elements in the vocabulary_file gs://qwiklabs-gcp-57137d462d1cebb5/hybrid_recommendation/preproc/vocabs/category_vocab.txt-00000-of-00001.\n",
      "INFO:tensorflow:Using default config.\n",
      "I0303 21:56:32.193813 140155275327232 tf_logging.py:116] Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpepm_55fb\n",
      "W0303 21:56:32.194348 140155275327232 tf_logging.py:126] Using temporary folder as model directory: /tmp/tmpepm_55fb\n",
      "INFO:tensorflow:Using config: {'_session_config': None, '_log_step_count_steps': 100, '_task_type': 'worker', '_save_summary_steps': 100, '_model_dir': '/tmp/tmpepm_55fb', '_num_worker_replicas': 1, '_global_id_in_cluster': 0, '_tf_random_seed': None, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_evaluation_master': '', '_is_chief': True, '_train_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f78534b1048>, '_num_ps_replicas': 0, '_service': None, '_master': '', '_task_id': 0, '_keep_checkpoint_every_n_hours': 10000}\n",
      "I0303 21:56:32.195137 140155275327232 tf_logging.py:116] Using config: {'_session_config': None, '_log_step_count_steps': 100, '_task_type': 'worker', '_save_summary_steps': 100, '_model_dir': '/tmp/tmpepm_55fb', '_num_worker_replicas': 1, '_global_id_in_cluster': 0, '_tf_random_seed': None, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_evaluation_master': '', '_is_chief': True, '_train_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f78534b1048>, '_num_ps_replicas': 0, '_service': None, '_master': '', '_task_id': 0, '_keep_checkpoint_every_n_hours': 10000}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "I0303 21:56:32.197738 140155275327232 tf_logging.py:116] Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 60 secs (eval_spec.throttle_secs) or training is finished.\n",
      "I0303 21:56:32.197992 140155275327232 tf_logging.py:116] Start train and evaluate loop. The evaluate will happen after 60 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0303 21:56:32.346200 140155275327232 tf_logging.py:116] Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "I0303 21:56:32.639728 140155275327232 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0303 21:56:43.482645 140155275327232 tf_logging.py:116] Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "I0303 21:56:43.484462 140155275327232 tf_logging.py:116] Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0303 21:56:43.874837 140155275327232 tf_logging.py:116] Graph was finalized.\n",
      "2019-03-03 21:56:43.875354: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-03-03 21:56:43.977981: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "2019-03-03 21:56:46.389213: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0303 21:56:46.666865 140155275327232 tf_logging.py:116] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0303 21:56:47.863052 140155275327232 tf_logging.py:116] Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpepm_55fb/model.ckpt.\n",
      "I0303 21:56:49.589184 140155275327232 tf_logging.py:116] Saving checkpoints for 1 into /tmp/tmpepm_55fb/model.ckpt.\n",
      "INFO:tensorflow:loss = 9.658207, step = 1\n",
      "I0303 21:56:49.983119 140155275327232 tf_logging.py:116] loss = 9.658207, step = 1\n",
      "INFO:tensorflow:global_step/sec: 6.89007\n",
      "I0303 21:57:04.496444 140155275327232 tf_logging.py:116] global_step/sec: 6.89007\n",
      "INFO:tensorflow:loss = 5.1049256, step = 101 (14.514 sec)\n",
      "I0303 21:57:04.497247 140155275327232 tf_logging.py:116] loss = 5.1049256, step = 101 (14.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.08919\n",
      "I0303 21:57:18.602488 140155275327232 tf_logging.py:116] global_step/sec: 7.08919\n",
      "INFO:tensorflow:loss = 4.6662316, step = 201 (14.106 sec)\n",
      "I0303 21:57:18.603410 140155275327232 tf_logging.py:116] loss = 4.6662316, step = 201 (14.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.10456\n",
      "I0303 21:57:32.677936 140155275327232 tf_logging.py:116] global_step/sec: 7.10456\n",
      "INFO:tensorflow:loss = 4.6349587, step = 301 (14.075 sec)\n",
      "I0303 21:57:32.678753 140155275327232 tf_logging.py:116] loss = 4.6349587, step = 301 (14.075 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 379 into /tmp/tmpepm_55fb/model.ckpt.\n",
      "I0303 21:57:43.873377 140155275327232 tf_logging.py:116] Saving checkpoints for 379 into /tmp/tmpepm_55fb/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.57885.\n",
      "I0303 21:57:45.060186 140155275327232 tf_logging.py:116] Loss for final step: 4.57885.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0303 21:57:45.243677 140155275327232 tf_logging.py:116] Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "I0303 21:57:45.534696 140155275327232 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0303 21:57:46.184854 140155275327232 tf_logging.py:116] Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-03-21:57:46\n",
      "I0303 21:57:46.207090 140155275327232 tf_logging.py:116] Starting evaluation at 2019-03-03-21:57:46\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0303 21:57:46.317072 140155275327232 tf_logging.py:116] Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpepm_55fb/model.ckpt-379\n",
      "I0303 21:57:46.317549 140155275327232 tf_logging.py:116] Restoring parameters from /tmp/tmpepm_55fb/model.ckpt-379\n",
      "2019-03-03 21:57:46.550097: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "2019-03-03 21:57:46.691182: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0303 21:57:46.908609 140155275327232 tf_logging.py:116] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0303 21:57:47.806623 140155275327232 tf_logging.py:116] Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-03-21:58:05\n",
      "I0303 21:58:05.911533 140155275327232 tf_logging.py:116] Finished evaluation at 2019-03-03-21:58:05\n",
      "INFO:tensorflow:Saving dict for global step 379: accuracy = 0.0291027, global_step = 379, loss = 5.730197, map_at_k = 0.05155515873015872, top_k_accuracy = 0.20981288\n",
      "I0303 21:58:05.912017 140155275327232 tf_logging.py:116] Saving dict for global step 379: accuracy = 0.0291027, global_step = 379, loss = 5.730197, map_at_k = 0.05155515873015872, top_k_accuracy = 0.20981288\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0303 21:58:06.638134 140155275327232 tf_logging.py:116] Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "I0303 21:58:07.120015 140155275327232 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0303 21:58:07.537012 140155275327232 tf_logging.py:116] Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default', 'predict_export_outputs']\n",
      "I0303 21:58:07.549893 140155275327232 tf_logging.py:116] Signatures INCLUDED in export for Predict: ['serving_default', 'predict_export_outputs']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "I0303 21:58:07.550220 140155275327232 tf_logging.py:116] Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "I0303 21:58:07.550324 140155275327232 tf_logging.py:116] Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpepm_55fb/model.ckpt-379\n",
      "I0303 21:58:07.579056 140155275327232 tf_logging.py:116] Restoring parameters from /tmp/tmpepm_55fb/model.ckpt-379\n",
      "2019-03-03 21:58:07.614984: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "2019-03-03 21:58:07.757457: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "I0303 21:58:07.948734 140155275327232 tf_logging.py:116] Assets added to graph.\n",
      "INFO:tensorflow:Assets written to: b\"/tmp/tmpepm_55fb/export/exporter/temp-b'1551650287'/assets\"\n",
      "I0303 21:58:07.960091 140155275327232 tf_logging.py:116] Assets written to: b\"/tmp/tmpepm_55fb/export/exporter/temp-b'1551650287'/assets\"\n",
      "INFO:tensorflow:SavedModel written to: b\"/tmp/tmpepm_55fb/export/exporter/temp-b'1551650287'/saved_model.pb\"\n",
      "I0303 21:58:08.406149 140155275327232 tf_logging.py:116] SavedModel written to: b\"/tmp/tmpepm_55fb/export/exporter/temp-b'1551650287'/saved_model.pb\"\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0303 21:58:08.566193 140155275327232 tf_logging.py:116] Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "I0303 21:58:08.878453 140155275327232 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0303 21:58:09.709238 140155275327232 tf_logging.py:116] Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "I0303 21:58:09.711194 140155275327232 tf_logging.py:116] Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0303 21:58:09.993425 140155275327232 tf_logging.py:116] Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpepm_55fb/model.ckpt-379\n",
      "I0303 21:58:09.994477 140155275327232 tf_logging.py:116] Restoring parameters from /tmp/tmpepm_55fb/model.ckpt-379\n",
      "2019-03-03 21:58:10.051707: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "2019-03-03 21:58:10.193850: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0303 21:58:10.400762 140155275327232 tf_logging.py:116] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0303 21:58:11.312114 140155275327232 tf_logging.py:116] Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 380 into /tmp/tmpepm_55fb/model.ckpt.\n",
      "I0303 21:58:13.321106 140155275327232 tf_logging.py:116] Saving checkpoints for 380 into /tmp/tmpepm_55fb/model.ckpt.\n",
      "INFO:tensorflow:loss = 5.7662845, step = 380\n",
      "I0303 21:58:15.003497 140155275327232 tf_logging.py:116] loss = 5.7662845, step = 380\n",
      "INFO:tensorflow:global_step/sec: 7.0224\n",
      "I0303 21:58:29.243378 140155275327232 tf_logging.py:116] global_step/sec: 7.0224\n",
      "INFO:tensorflow:loss = 4.9069424, step = 480 (14.241 sec)\n",
      "I0303 21:58:29.244202 140155275327232 tf_logging.py:116] loss = 4.9069424, step = 480 (14.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.09065\n",
      "I0303 21:58:43.346474 140155275327232 tf_logging.py:116] global_step/sec: 7.09065\n",
      "INFO:tensorflow:loss = 4.2994094, step = 580 (14.103 sec)\n",
      "I0303 21:58:43.347347 140155275327232 tf_logging.py:116] loss = 4.2994094, step = 580 (14.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.06172\n",
      "I0303 21:58:57.507317 140155275327232 tf_logging.py:116] global_step/sec: 7.06172\n",
      "INFO:tensorflow:loss = 4.784443, step = 680 (14.161 sec)\n",
      "I0303 21:58:57.508310 140155275327232 tf_logging.py:116] loss = 4.784443, step = 680 (14.161 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 767 into /tmp/tmpepm_55fb/model.ckpt.\n",
      "I0303 21:59:09.754509 140155275327232 tf_logging.py:116] Saving checkpoints for 767 into /tmp/tmpepm_55fb/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.4156494.\n",
      "I0303 21:59:11.248545 140155275327232 tf_logging.py:116] Loss for final step: 4.4156494.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0303 21:59:11.382903 140155275327232 tf_logging.py:116] Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "I0303 21:59:11.684290 140155275327232 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0303 21:59:12.361726 140155275327232 tf_logging.py:116] Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-03-21:59:12\n",
      "I0303 21:59:12.384118 140155275327232 tf_logging.py:116] Starting evaluation at 2019-03-03-21:59:12\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0303 21:59:12.494415 140155275327232 tf_logging.py:116] Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpepm_55fb/model.ckpt-767\n",
      "I0303 21:59:12.495049 140155275327232 tf_logging.py:116] Restoring parameters from /tmp/tmpepm_55fb/model.ckpt-767\n",
      "2019-03-03 21:59:12.538439: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "2019-03-03 21:59:12.711380: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0303 21:59:13.052071 140155275327232 tf_logging.py:116] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0303 21:59:14.175479 140155275327232 tf_logging.py:116] Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-03-21:59:32\n",
      "I0303 21:59:32.127979 140155275327232 tf_logging.py:116] Finished evaluation at 2019-03-03-21:59:32\n",
      "INFO:tensorflow:Saving dict for global step 767: accuracy = 0.028321419, global_step = 767, loss = 5.7045183, map_at_k = 0.06665138888888894, top_k_accuracy = 0.20090629\n",
      "I0303 21:59:32.128408 140155275327232 tf_logging.py:116] Saving dict for global step 767: accuracy = 0.028321419, global_step = 767, loss = 5.7045183, map_at_k = 0.06665138888888894, top_k_accuracy = 0.20090629\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0303 21:59:32.619417 140155275327232 tf_logging.py:116] Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "I0303 21:59:33.107269 140155275327232 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0303 21:59:33.524990 140155275327232 tf_logging.py:116] Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default', 'predict_export_outputs']\n",
      "I0303 21:59:33.536743 140155275327232 tf_logging.py:116] Signatures INCLUDED in export for Predict: ['serving_default', 'predict_export_outputs']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "I0303 21:59:33.537065 140155275327232 tf_logging.py:116] Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "I0303 21:59:33.537174 140155275327232 tf_logging.py:116] Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpepm_55fb/model.ckpt-767\n",
      "I0303 21:59:33.567397 140155275327232 tf_logging.py:116] Restoring parameters from /tmp/tmpepm_55fb/model.ckpt-767\n",
      "2019-03-03 21:59:33.599647: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "2019-03-03 21:59:33.748736: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "I0303 21:59:33.948588 140155275327232 tf_logging.py:116] Assets added to graph.\n",
      "INFO:tensorflow:Assets written to: b\"/tmp/tmpepm_55fb/export/exporter/temp-b'1551650373'/assets\"\n",
      "I0303 21:59:33.960109 140155275327232 tf_logging.py:116] Assets written to: b\"/tmp/tmpepm_55fb/export/exporter/temp-b'1551650373'/assets\"\n",
      "INFO:tensorflow:SavedModel written to: b\"/tmp/tmpepm_55fb/export/exporter/temp-b'1551650373'/saved_model.pb\"\n",
      "I0303 21:59:34.431189 140155275327232 tf_logging.py:116] SavedModel written to: b\"/tmp/tmpepm_55fb/export/exporter/temp-b'1551650373'/saved_model.pb\"\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0303 21:59:34.593732 140155275327232 tf_logging.py:116] Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "I0303 21:59:34.898692 140155275327232 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0303 21:59:36.098418 140155275327232 tf_logging.py:116] Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "I0303 21:59:36.100326 140155275327232 tf_logging.py:116] Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0303 21:59:36.367033 140155275327232 tf_logging.py:116] Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpepm_55fb/model.ckpt-767\n",
      "I0303 21:59:36.368263 140155275327232 tf_logging.py:116] Restoring parameters from /tmp/tmpepm_55fb/model.ckpt-767\n",
      "2019-03-03 21:59:36.425107: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "2019-03-03 21:59:36.571734: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0303 21:59:36.899338 140155275327232 tf_logging.py:116] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0303 21:59:38.030842 140155275327232 tf_logging.py:116] Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 768 into /tmp/tmpepm_55fb/model.ckpt.\n",
      "I0303 21:59:42.088598 140155275327232 tf_logging.py:116] Saving checkpoints for 768 into /tmp/tmpepm_55fb/model.ckpt.\n",
      "INFO:tensorflow:loss = 5.7117567, step = 768\n",
      "I0303 21:59:42.796678 140155275327232 tf_logging.py:116] loss = 5.7117567, step = 768\n",
      "INFO:tensorflow:global_step/sec: 6.97626\n",
      "I0303 21:59:57.130778 140155275327232 tf_logging.py:116] global_step/sec: 6.97626\n",
      "INFO:tensorflow:loss = 4.7860394, step = 868 (14.335 sec)\n",
      "I0303 21:59:57.131788 140155275327232 tf_logging.py:116] loss = 4.7860394, step = 868 (14.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.09292\n",
      "I0303 22:00:11.229361 140155275327232 tf_logging.py:116] global_step/sec: 7.09292\n",
      "INFO:tensorflow:loss = 4.3201275, step = 968 (14.098 sec)\n",
      "I0303 22:00:11.230241 140155275327232 tf_logging.py:116] loss = 4.3201275, step = 968 (14.098 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpepm_55fb/model.ckpt.\n",
      "I0303 22:00:15.743830 140155275327232 tf_logging.py:116] Saving checkpoints for 1000 into /tmp/tmpepm_55fb/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.8835673.\n",
      "I0303 22:00:16.980680 140155275327232 tf_logging.py:116] Loss for final step: 4.8835673.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0303 22:00:17.110417 140155275327232 tf_logging.py:116] Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "I0303 22:00:17.408502 140155275327232 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0303 22:00:18.046133 140155275327232 tf_logging.py:116] Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-03-22:00:18\n",
      "I0303 22:00:18.068003 140155275327232 tf_logging.py:116] Starting evaluation at 2019-03-03-22:00:18\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0303 22:00:18.178604 140155275327232 tf_logging.py:116] Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpepm_55fb/model.ckpt-1000\n",
      "I0303 22:00:18.179097 140155275327232 tf_logging.py:116] Restoring parameters from /tmp/tmpepm_55fb/model.ckpt-1000\n",
      "2019-03-03 22:00:18.222277: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "2019-03-03 22:00:18.364856: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0303 22:00:18.603348 140155275327232 tf_logging.py:116] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0303 22:00:19.504082 140155275327232 tf_logging.py:116] Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-03-22:00:37\n",
      "I0303 22:00:37.269237 140155275327232 tf_logging.py:116] Finished evaluation at 2019-03-03-22:00:37\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.02230556, global_step = 1000, loss = 5.523609, map_at_k = 0.05578293650793651, top_k_accuracy = 0.20649244\n",
      "I0303 22:00:37.270079 140155275327232 tf_logging.py:116] Saving dict for global step 1000: accuracy = 0.02230556, global_step = 1000, loss = 5.523609, map_at_k = 0.05578293650793651, top_k_accuracy = 0.20649244\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0303 22:00:37.910380 140155275327232 tf_logging.py:116] Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "I0303 22:00:38.440302 140155275327232 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0303 22:00:38.888873 140155275327232 tf_logging.py:116] Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default', 'predict_export_outputs']\n",
      "I0303 22:00:38.900990 140155275327232 tf_logging.py:116] Signatures INCLUDED in export for Predict: ['serving_default', 'predict_export_outputs']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "I0303 22:00:38.901294 140155275327232 tf_logging.py:116] Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "I0303 22:00:38.901423 140155275327232 tf_logging.py:116] Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpepm_55fb/model.ckpt-1000\n",
      "I0303 22:00:38.930938 140155275327232 tf_logging.py:116] Restoring parameters from /tmp/tmpepm_55fb/model.ckpt-1000\n",
      "2019-03-03 22:00:38.960989: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "2019-03-03 22:00:39.113525: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "I0303 22:00:39.292509 140155275327232 tf_logging.py:116] Assets added to graph.\n",
      "INFO:tensorflow:Assets written to: b\"/tmp/tmpepm_55fb/export/exporter/temp-b'1551650438'/assets\"\n",
      "I0303 22:00:39.303107 140155275327232 tf_logging.py:116] Assets written to: b\"/tmp/tmpepm_55fb/export/exporter/temp-b'1551650438'/assets\"\n",
      "INFO:tensorflow:SavedModel written to: b\"/tmp/tmpepm_55fb/export/exporter/temp-b'1551650438'/saved_model.pb\"\n",
      "I0303 22:00:39.764860 140155275327232 tf_logging.py:116] SavedModel written to: b\"/tmp/tmpepm_55fb/export/exporter/temp-b'1551650438'/saved_model.pb\"\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "echo \"bucket=${BUCKET}\"\n",
    "rm -rf hybrid_recommendation_trained\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/hybrid_recommendations_module\n",
    "python -m trainer.task \\\n",
    "  --bucket=${BUCKET} \\\n",
    "  --train_data_paths=gs://${BUCKET}/hybrid_recommendation/preproc/features/train.csv* \\\n",
    "  --eval_data_paths=gs://${BUCKET}/hybrid_recommendation/preproc/features/eval.csv* \\\n",
    "  --output_dir=${OUTDIR} \\\n",
    "  --batch_size=128 \\\n",
    "  --learning_rate=0.1 \\\n",
    "  --hidden_units=\"256 128 64\" \\\n",
    "  --content_id_embedding_dimensions=10 \\\n",
    "  --author_embedding_dimensions=10 \\\n",
    "  --top_k=10 \\\n",
    "  --train_steps=1000 \\\n",
    "  --start_delay_secs=30 \\\n",
    "  --throttle_secs=60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on Google Cloud ML Engine\n",
    "If our module locally trained fine, let's now use of the power of ML Engine to scale it out on Google Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-57137d462d1cebb5/hybrid_recommendation/small_trained_model us-east1 hybrid_recommendation_190303_220416\n",
      "jobId: hybrid_recommendation_190303_220416\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "Job [hybrid_recommendation_190303_220416] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe hybrid_recommendation_190303_220416\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs hybrid_recommendation_190303_220416\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "OUTDIR=gs://${BUCKET}/hybrid_recommendation/small_trained_model\n",
    "JOBNAME=hybrid_recommendation_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$(pwd)/hybrid_recommendations_module/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --runtime-version=$TFVERSION \\\n",
    "  -- \\\n",
    "  --bucket=${BUCKET} \\\n",
    "  --train_data_paths=gs://${BUCKET}/hybrid_recommendation/preproc/features/train.csv* \\\n",
    "  --eval_data_paths=gs://${BUCKET}/hybrid_recommendation/preproc/features/eval.csv* \\\n",
    "  --output_dir=${OUTDIR} \\\n",
    "  --batch_size=128 \\\n",
    "  --learning_rate=0.1 \\\n",
    "  --hidden_units=\"256 128 64\" \\\n",
    "  --content_id_embedding_dimensions=10 \\\n",
    "  --author_embedding_dimensions=10 \\\n",
    "  --top_k=10 \\\n",
    "  --train_steps=1000 \\\n",
    "  --start_delay_secs=30 \\\n",
    "  --throttle_secs=30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some hyperparameter tuning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2019-03-03T22:04:19Z'\n",
      "endTime: '2019-03-03T22:09:54Z'\n",
      "etag: fOsa-x79N6c=\n",
      "jobId: hybrid_recommendation_190303_220416\n",
      "startTime: '2019-03-03T22:08:53Z'\n",
      "state: SUCCEEDED\n",
      "trainingInput:\n",
      "  args:\n",
      "  - --bucket=qwiklabs-gcp-57137d462d1cebb5\n",
      "  - --train_data_paths=gs://qwiklabs-gcp-57137d462d1cebb5/hybrid_recommendation/preproc/features/train.csv*\n",
      "  - --eval_data_paths=gs://qwiklabs-gcp-57137d462d1cebb5/hybrid_recommendation/preproc/features/eval.csv*\n",
      "  - --output_dir=gs://qwiklabs-gcp-57137d462d1cebb5/hybrid_recommendation/small_trained_model\n",
      "  - --batch_size=128\n",
      "  - --learning_rate=0.1\n",
      "  - --hidden_units=256 128 64\n",
      "  - --content_id_embedding_dimensions=10\n",
      "  - --author_embedding_dimensions=10\n",
      "  - --top_k=10\n",
      "  - --train_steps=1000\n",
      "  - --start_delay_secs=30\n",
      "  - --throttle_secs=30\n",
      "  jobDir: gs://qwiklabs-gcp-57137d462d1cebb5/hybrid_recommendation/small_trained_model\n",
      "  packageUris:\n",
      "  - gs://qwiklabs-gcp-57137d462d1cebb5/hybrid_recommendation_190303_220416/b76ac07eadcef8aea67375971b8b5dbf76fd669c5e3a8c56c67aefd2862b0136/hybrid_recommendation-0.1.tar.gz\n",
      "  pythonModule: trainer.task\n",
      "  region: us-east1\n",
      "  runtimeVersion: '1.8'\n",
      "  scaleTier: STANDARD_1\n",
      "trainingOutput:\n",
      "  consumedMLUnits: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "View job in the Cloud Console at:\n",
      "https://console.cloud.google.com/ml/jobs/hybrid_recommendation_190303_220416?project=qwiklabs-gcp-57137d462d1cebb5\n",
      "\n",
      "View logs at:\n",
      "https://console.cloud.google.com/logs?resource=ml.googleapis.com%2Fjob_id%2Fhybrid_recommendation_190303_220416&project=qwiklabs-gcp-57137d462d1cebb5\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud ml-engine jobs describe hybrid_recommendation_190303_220416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hyperparam.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile hyperparam.yaml\n",
    "trainingInput:\n",
    "  hyperparameters:\n",
    "    goal: MAXIMIZE\n",
    "    maxTrials: 5\n",
    "    maxParallelTrials: 1\n",
    "    hyperparameterMetricTag: accuracy\n",
    "    params:\n",
    "    - parameterName: batch_size\n",
    "      type: INTEGER\n",
    "      minValue: 8\n",
    "      maxValue: 64\n",
    "      scaleType: UNIT_LINEAR_SCALE\n",
    "    - parameterName: learning_rate\n",
    "      type: DOUBLE\n",
    "      minValue: 0.01\n",
    "      maxValue: 0.1\n",
    "      scaleType: UNIT_LINEAR_SCALE\n",
    "    - parameterName: hidden_units\n",
    "      type: CATEGORICAL\n",
    "      categoricalValues: ['1024 512 256', '1024 512 128', '1024 256 128', '512 256 128', '1024 512 64', '1024 256 64', '512 256 64', '1024 128 64', '512 128 64', '256 128 64', '1024 512 32', '1024 256 32', '512 256 32', '1024 128 32', '512 128 32', '256 128 32', '1024 64 32', '512 64 32', '256 64 32', '128 64 32']\n",
    "    - parameterName: content_id_embedding_dimensions\n",
    "      type: INTEGER\n",
    "      minValue: 5\n",
    "      maxValue: 250\n",
    "      scaleType: UNIT_LOG_SCALE\n",
    "    - parameterName: author_embedding_dimensions\n",
    "      type: INTEGER\n",
    "      minValue: 5\n",
    "      maxValue: 30\n",
    "      scaleType: UNIT_LINEAR_SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-57137d462d1cebb5/hybrid_recommendation/hypertuning us-east1 hybrid_recommendation_190303_221204\n",
      "jobId: hybrid_recommendation_190303_221204\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "Job [hybrid_recommendation_190303_221204] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe hybrid_recommendation_190303_221204\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs hybrid_recommendation_190303_221204\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "OUTDIR=gs://${BUCKET}/hybrid_recommendation/hypertuning\n",
    "JOBNAME=hybrid_recommendation_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$(pwd)/hybrid_recommendations_module/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --runtime-version=$TFVERSION \\\n",
    "  --config=hyperparam.yaml \\\n",
    "  -- \\\n",
    "  --bucket=${BUCKET} \\\n",
    "  --train_data_paths=gs://${BUCKET}/hybrid_recommendation/preproc/features/train.csv* \\\n",
    "  --eval_data_paths=gs://${BUCKET}/hybrid_recommendation/preproc/features/eval.csv* \\\n",
    "  --output_dir=${OUTDIR} \\\n",
    "  --batch_size=128 \\\n",
    "  --learning_rate=0.1 \\\n",
    "  --hidden_units=\"256 128 64\" \\\n",
    "  --content_id_embedding_dimensions=10 \\\n",
    "  --author_embedding_dimensions=10 \\\n",
    "  --top_k=10 \\\n",
    "  --train_steps=1000 \\\n",
    "  --start_delay_secs=30 \\\n",
    "  --throttle_secs=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2019-03-03T22:12:07Z'\n",
      "etag: ZslAO3kfE90=\n",
      "jobId: hybrid_recommendation_190303_221204\n",
      "startTime: '2019-03-03T22:12:10Z'\n",
      "state: RUNNING\n",
      "trainingInput:\n",
      "  args:\n",
      "  - --bucket=qwiklabs-gcp-57137d462d1cebb5\n",
      "  - --train_data_paths=gs://qwiklabs-gcp-57137d462d1cebb5/hybrid_recommendation/preproc/features/train.csv*\n",
      "  - --eval_data_paths=gs://qwiklabs-gcp-57137d462d1cebb5/hybrid_recommendation/preproc/features/eval.csv*\n",
      "  - --output_dir=gs://qwiklabs-gcp-57137d462d1cebb5/hybrid_recommendation/hypertuning\n",
      "  - --batch_size=128\n",
      "  - --learning_rate=0.1\n",
      "  - --hidden_units=256 128 64\n",
      "  - --content_id_embedding_dimensions=10\n",
      "  - --author_embedding_dimensions=10\n",
      "  - --top_k=10\n",
      "  - --train_steps=1000\n",
      "  - --start_delay_secs=30\n",
      "  - --throttle_secs=30\n",
      "  hyperparameters:\n",
      "    goal: MAXIMIZE\n",
      "    hyperparameterMetricTag: accuracy\n",
      "    maxParallelTrials: 1\n",
      "    maxTrials: 5\n",
      "    params:\n",
      "    - maxValue: 64.0\n",
      "      minValue: 8.0\n",
      "      parameterName: batch_size\n",
      "      scaleType: UNIT_LINEAR_SCALE\n",
      "      type: INTEGER\n",
      "    - maxValue: 0.1\n",
      "      minValue: 0.01\n",
      "      parameterName: learning_rate\n",
      "      scaleType: UNIT_LINEAR_SCALE\n",
      "      type: DOUBLE\n",
      "    - categoricalValues:\n",
      "      - 1024 512 256\n",
      "      - 1024 512 128\n",
      "      - 1024 256 128\n",
      "      - 512 256 128\n",
      "      - 1024 512 64\n",
      "      - 1024 256 64\n",
      "      - 512 256 64\n",
      "      - 1024 128 64\n",
      "      - 512 128 64\n",
      "      - 256 128 64\n",
      "      - 1024 512 32\n",
      "      - 1024 256 32\n",
      "      - 512 256 32\n",
      "      - 1024 128 32\n",
      "      - 512 128 32\n",
      "      - 256 128 32\n",
      "      - 1024 64 32\n",
      "      - 512 64 32\n",
      "      - 256 64 32\n",
      "      - 128 64 32\n",
      "      parameterName: hidden_units\n",
      "      type: CATEGORICAL\n",
      "    - maxValue: 250.0\n",
      "      minValue: 5.0\n",
      "      parameterName: content_id_embedding_dimensions\n",
      "      scaleType: UNIT_LOG_SCALE\n",
      "      type: INTEGER\n",
      "    - maxValue: 30.0\n",
      "      minValue: 5.0\n",
      "      parameterName: author_embedding_dimensions\n",
      "      scaleType: UNIT_LINEAR_SCALE\n",
      "      type: INTEGER\n",
      "  jobDir: gs://qwiklabs-gcp-57137d462d1cebb5/hybrid_recommendation/hypertuning\n",
      "  packageUris:\n",
      "  - gs://qwiklabs-gcp-57137d462d1cebb5/hybrid_recommendation_190303_221204/f65aed0a2117479e29ee00392cdb2b049993d0a14c28d129672c03667773c7b7/hybrid_recommendation-0.1.tar.gz\n",
      "  pythonModule: trainer.task\n",
      "  region: us-east1\n",
      "  runtimeVersion: '1.8'\n",
      "  scaleTier: STANDARD_1\n",
      "trainingOutput:\n",
      "  completedTrialCount: '4'\n",
      "  consumedMLUnits: 3.95\n",
      "  isHyperparameterTuningJob: true\n",
      "  trials:\n",
      "  - finalMetric:\n",
      "      objectiveValue: 0.0266417\n",
      "      trainingStep: '1005'\n",
      "    hyperparameters:\n",
      "      author_embedding_dimensions: '9'\n",
      "      batch_size: '32'\n",
      "      content_id_embedding_dimensions: '9'\n",
      "      hidden_units: 128 64 32\n",
      "      learning_rate: '0.012269170284271241'\n",
      "    trialId: '4'\n",
      "  - finalMetric:\n",
      "      objectiveValue: 0.00910192\n",
      "      trainingStep: '1007'\n",
      "    hyperparameters:\n",
      "      author_embedding_dimensions: '6'\n",
      "      batch_size: '35'\n",
      "      content_id_embedding_dimensions: '205'\n",
      "      hidden_units: 1024 64 32\n",
      "      learning_rate: '0.067416160106658934'\n",
      "    trialId: '1'\n",
      "  - hyperparameters:\n",
      "      author_embedding_dimensions: '30'\n",
      "      batch_size: '57'\n",
      "      content_id_embedding_dimensions: '117'\n",
      "      hidden_units: 256 64 32\n",
      "      learning_rate: '0.034834047555923467'\n",
      "    trialId: '2'\n",
      "  - hyperparameters:\n",
      "      author_embedding_dimensions: '23'\n",
      "      batch_size: '37'\n",
      "      content_id_embedding_dimensions: '9'\n",
      "      hidden_units: 256 128 32\n",
      "      learning_rate: '0.097884606122970591'\n",
      "    trialId: '3'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "View job in the Cloud Console at:\n",
      "https://console.cloud.google.com/ml/jobs/hybrid_recommendation_190303_221204?project=qwiklabs-gcp-57137d462d1cebb5\n",
      "\n",
      "View logs at:\n",
      "https://console.cloud.google.com/logs?resource=ml.googleapis.com%2Fjob_id%2Fhybrid_recommendation_190303_221204&project=qwiklabs-gcp-57137d462d1cebb5\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud ml-engine jobs describe hybrid_recommendation_190303_221204"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the best hyperparameters, run a big training job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "OUTDIR=gs://${BUCKET}/hybrid_recommendation/big_trained_model\n",
    "JOBNAME=hybrid_recommendation_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$(pwd)/hybrid_recommendations_module/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --runtime-version=$TFVERSION \\\n",
    "  -- \\\n",
    "  --bucket=${BUCKET} \\\n",
    "  --train_data_paths=gs://${BUCKET}/hybrid_recommendation/preproc/features/train.csv* \\\n",
    "  --eval_data_paths=gs://${BUCKET}/hybrid_recommendation/preproc/features/eval.csv* \\\n",
    "  --output_dir=${OUTDIR} \\\n",
    "  --batch_size=128 \\\n",
    "  --learning_rate=0.1 \\\n",
    "  --hidden_units=\"256 128 64\" \\\n",
    "  --content_id_embedding_dimensions=10 \\\n",
    "  --author_embedding_dimensions=10 \\\n",
    "  --top_k=10 \\\n",
    "  --train_steps=10000 \\\n",
    "  --start_delay_secs=30 \\\n",
    "  --throttle_secs=30"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
